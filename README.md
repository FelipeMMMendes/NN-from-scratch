# NN-from-scratch
Esse repositÃ³rio Ã© fruto da sÃ©rie de videos do canal **sentdex**, que implementou uma rede neural em python.

Uma rede neural Ã© um modelo que simula o modo de aprendizado humano, com suas sinapses e neurÃ´nios.

![REDE NEURAL](https://i.imgur.com/PeldHjy.png)

- Temos uma camada de entrada no inÃ­cio, camadas ocultas no meio (podem ser vÃ¡rias) e uma camada de saÃ­da no final.
- Cada bolinha azul dessas Ã© um neurÃ´nio e eles estÃ£o conectados uns com os outros.
- Em uma rede neural o processamento do dado comeÃ§a na camada de entrada, ele Ã© passado para as camadas ocultas e depois Ã© passado para a camada de saÃ­da.

Para treinar a rede neural, Ã© feito o balanceamento dos **pesos** e dos **biases.**

- **Pesos:** SÃ£o os padrÃµes para a forÃ§a do sinal do neurÃ´nio, esse valor vai determinar a influÃªncia dos dados de entrada no produto da saÃ­da de cada neurÃ´nio. Pense neles como os nÃºmeros que ajustam o impacto dos dados que estÃ£o entrando. Eles podem aumentar ou diminuir a importÃ¢ncia de informaÃ§Ãµes especÃ­ficas. **Em essÃªncia, os pesos sÃ£o a forma da rede neural aprender com os dados. Eles capturam as relaÃ§Ãµes entre as features de entrada e de saÃ­da alvo, permitindo que a rede neural generalize e faÃ§a prediÃ§Ãµes em dados que ela nÃ£o viu.**

- **Bias:** Acrescentam uma camada adicional deÂ flexibilidadeÂ para as redes neurais. Biases sÃ£o constantes associadas com cada neurÃ´nio. Ao contrÃ¡rio dos pesos, o bias nÃ£o estÃ¡ relacionado com dados especÃ­ficos de entrada do neurÃ´nio, mas sÃ£o acrescentados aos dados de saÃ­da do neurÃ´nios. Bias sÃ£o como um limite, permitindo que alguns neurÃ´nios sejam ativados mesmo que a soma dos pesos dos dados que entraram nÃ£o seja o suficiente por conta prÃ³pria. Os biases introduzem um nÃ­vel de adaptabilidade que garante que a rede possa aprender e fazer prediÃ§Ãµes efetivamente. Para ficar claro, imagine um neurÃ´nio que processe o nÃ­vel de brilho do pixel de uma imagem, sem o bias, esse neurÃ´nio sÃ³ seria ativado quando o nÃ­vel de brilho do pixel estivesse exatamente em um certo limite, mas colocando o bias, vocÃª permite que o neurÃ´nio ative mesmo quando o brilho estiver um pouco menor ou acima do limite. Essa flexibilidade Ã© crucial porque os dados do mundo real raramente estÃ£o alinhados em um exato limite. Dessa forma, os biases permitem que os neurÃ´nios ativem em vÃ¡rias condiÃ§Ãµes de entrada, fazendo com que as redes neurais fiquem mais robustas e capazes de lidar com dados complexos. Durante o treino, os biases sÃ£o ajustados para otimizar a performance da rede neural. 

![REDE NEURAL II](https://i.imgur.com/fSBTsUP.png)

- No exemplo acima, temos 224 pesos, que sÃ£o representados pelas conexÃµes de saÃ­da â†’ entrada entre os neurÃ´nios.
- Temos 26 biases, cada neurÃ´nio tem o seu prÃ³prio (menos os da camada de entrada).
- Nesse sentido, temos 250 parÃ¢metros ajustÃ¡veis.

### Processo de aprendizado: Forward e Backward Propagation

#### **A. Forward Propagation**
A propagaÃ§Ã£o para frente Ã© a fase inicial de processamento dos dados de entrada atravÃ©s da rede neural para formar o resultado ou prediÃ§Ã£o.

1. **Camada de entrada**: Os dados sÃ£o inseridos na camada de entrada da rede neural.
2. **Soma ponderada dos pesos**: Cada neurÃ´nio nas camadas subsequentes calcula a soma dos pesos dos dados que recebem, em que os pesos sÃ£o os parÃ¢metros ajustÃ¡veis.
3. **Acrescentando os biases**: SÃ£o acrescentados os bias associados aos neurÃ´nios para cada soma ponderada do passo anterior. Isso introduz um limite para ativaÃ§Ã£o.
4. **FunÃ§Ã£o de AtivaÃ§Ã£o**: Os resultados da soma ponderada com o bias Ã© passado atravÃ©s de uma funÃ§Ã£o de ativaÃ§Ã£o. Essa funÃ§Ã£o determina se o neurÃ´nio deve ativar ou continuar dormente baseado no valor calculado.
5. **PropagaÃ§Ã£o**: O resultado de saÃ­da uma das camadas vira a entrada para a camada seguinte, e o processo se repete atÃ© que a camada de saÃ­da produza a prediÃ§Ã£o da rede.

**Essa lÃ³gica de funcionamento foi implementada no notebook do repositÃ³rio.**

Abaixo segue um exemplo visual de funcionamento de rede neural:

![REDE NEURAL GATO](https://i.imgur.com/2kKW6Q5.png)
![REDE NEURAL GATO](https://i.imgur.com/AZvTtgI.png)
![REDE NEURAL GATO](https://i.imgur.com/iK7k2IV.png)

A foto de um gato foi inserida na rede neural e ela identificou ele corretamente como um gato, pode-se dizer que o neurÃ´nio de gato na camada de saÃ­da foi o mais forte.

#### **B. Backward Propagation**

Depois que a rede neural fez uma prediÃ§Ã£o, precisamos avaliar o quÃ£o certeira ela foi e tambÃ©m precisamos fazer ajustes para melhorar futuras prediÃ§Ãµes.

1. **CÃ¡lculos dos erros**: A prediÃ§Ã£o da rede neural Ã© comparado com o fato real, o erro resultante, chamado de **loss** ou **cost**, mede a disparidade entre prediÃ§Ã£o e realidade.
2. **Gradiente Descendente**: A propagaÃ§Ã£o para trÃ¡s envolve minimizar esse erro. Para fazer isso, a rede calcula o gradiente do erro considerante os pesos e as biases. Esse gradiente aponta na direÃ§Ã£o da diminuiÃ§Ã£o mais acentuada do erro.
3. **AtualizaÃ§Ã£o de Peso e Bias**: A rede neural usa as informaÃ§Ãµes que obteve com o gradiente descendente para ajustar os pesos e os biases de toda a rede neural. O objetivo Ã© encontrar os valores que minimizam o erro.
4. **Processo de IteraÃ§Ã£o**: Esse processo de forward e backward propagation Ã© repetido iterativamente em lotes de dados de treino, com cada iteraÃ§Ã£o, os pesos e os biases da rede se aproximam de valores que minimizam o erro.

**Em resumo, a propagaÃ§Ã£o para trÃ¡s ajusta os parÃ¢metros da rede, fazendo com que fiquem com mais acurÃ¡cia. Esse processo de iteraÃ§Ã£o continua atÃ© que a rede alcance um nÃ­vel satisfatÃ³rio de performance nos dados de treino**

### **CÃ¡lculo da SaÃ­da do NeurÃ´nio de forma visual**
 A saÃ­da do neurÃ´nio Ã© dada por:  

\[
\text{SaÃ­da NeurÃ´nio} = \text{Input} \times \text{Peso} + \text{Bias}
\]  
Ela se assemelha a uma funÃ§Ã£o de primeiro grau, esse seria o comportamento dela:

![NN_formula](https://i.imgur.com/lzEKc4S.gif)

### **Shape**:
Para trabalhar com redes neurais e deep learning, precisamos entender o conceito de **shape** ou formato nas linguagens de programaÃ§Ã£o.

No contexto de **deep learning em python**, vamos ver as formas que o **numpy** reconhece:

![shape](https://i.imgur.com/sNTvXjn.png)

Acima temos uma lista com 4 elementos, de uma dimensÃ£o, entÃ£o Ã© um vetor. Ela tem 4 elementos, entÃ£o o shape dela Ã© (4, ).

![shape](https://i.imgur.com/rjvZZn2.png)

Acima temos uma lista com duas listas dentro, cada uma com 4 elementos. Isso Ã© uma matriz, o shape dela Ã© (2, 4).

![shape](https://i.imgur.com/5qYQjEk.png)

Acima temos uma lista, dentro dessa lista temos 3 outras listas, dentro dessas 3 outras listas, temos 2 listas em cada, em cada uma dessas duas listas temos 4 elementos.

Temos outra forma que Ã© o **tensor**, de forma bem rasa, um tensor Ã© um objeto que pode ser representado como um array, ele nÃ£o Ã© um simples array, mas no contexto de programaÃ§Ã£o e deep learning ele pode ser representado e trabalhado como um array.  

### **Dot product**

Pegando o conceito dos tipos de array acima, podemos fazer operaÃ§Ãµes entre eles, no caso do **Dot Product**, estamos falando da **multiplicaÃ§Ã£o** de dois arrays, e ele nos retorna somente um valor. Vale ressaltar que o dot product vem da biblioteca do numpy.

![dot_product](https://i.imgur.com/xh5txKP.png)

### Batches

Usamos lotes nos inputs na camada de entrada da rede porque assim facilita o aprendizado para o modelo. Se usarmos apenas uma entrada por vez para treinar o modelo, ele terÃ¡ mais dificuldades para fazer os ajustes. Se usarmos mais entradas por vezes, o modelo irÃ¡ se ajustar com mais facilidade.

![dot_product](https://i.imgur.com/dkR4r0K.gif)

No exemplo acima, os pontos que surgem sÃ£o os dados que pedimos para a rede se ajustar, como estamos passando dados de entrada com lotes de tamanho 1, percebe-se que a linha se movimenta e muito.

![dot_product](https://i.imgur.com/JESirG6.gif)

JÃ¡ nesse outro exemplo, a linha vai se adaptando, e quando se ajusta totalmente, percebe-se que ela vai se movendo muito pouco, isso porque estamos agora passando dados de entrada com lotes com tamanho 32.

### FunÃ§Ãµes de AtivaÃ§Ã£o

Como vimos acima, os resultados de uma rede neural possuem uma relaÃ§Ã£o linear, para introduzirmos uma **NÃ£o-Linearidade** na rede neural e assim possibilitarmos que ela compreenda melhor relaÃ§Ãµes mais complexas nos dados, usamos as **funÃ§Ãµes de ativaÃ§Ã£o**.

A ideia Ã© que as funÃ§Ãµes de ativaÃ§Ã£o sÃ£o aplicadas nos resultados dos neurÃ´nios, apÃ³s todas as operaÃ§Ãµes.

![products](https://miro.medium.com/v2/resize:fit:828/format:webp/1*bUNxrEy2KjKNrwMRo8eS9w.png)

Depois de pegar os resultados $z_{1}$ e $z_{2}$ aplicamos eles na funÃ§Ã£o de ativaÃ§Ã£o ðœŽ.

![activation function >](https://miro.medium.com/v2/resize:fit:278/format:webp/1*9DfvAg_pENO5MX0ELeY_kg.png)


