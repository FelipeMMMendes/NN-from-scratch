# NN-from-scratch
Esse reposit√≥rio √© fruto da s√©rie de videos do canal **sentdex**, que implementou uma rede neural em python.

Uma rede neural √© um modelo que simula o modo de aprendizado humano, com suas sinapses e neur√¥nios.

![REDE NEURAL](https://i.imgur.com/PeldHjy.png)

- Temos uma camada de entrada no in√≠cio, camadas ocultas no meio (podem ser v√°rias) e uma camada de sa√≠da no final.
- Cada bolinha azul dessas √© um neur√¥nio e eles est√£o conectados uns com os outros.
- Em uma rede neural o processamento do dado come√ßa na camada de entrada, ele √© passado para as camadas ocultas e depois √© passado para a camada de sa√≠da.

Para treinar a rede neural, √© feito o balanceamento dos **pesos** e dos **biases.**

- **Pesos:** S√£o os padr√µes para a for√ßa do sinal do neur√¥nio, esse valor vai determinar a influ√™ncia dos dados de entrada no produto da sa√≠da de cada neur√¥nio. Pense neles como os n√∫meros que ajustam o impacto dos dados que est√£o entrando. Eles podem aumentar ou diminuir a import√¢ncia de informa√ß√µes espec√≠ficas. **Em ess√™ncia, os pesos s√£o a forma da rede neural aprender com os dados. Eles capturam as rela√ß√µes entre as features de entrada e de sa√≠da alvo, permitindo que a rede neural generalize e fa√ßa predi√ß√µes em dados que ela n√£o viu.**

- **Bias:** Acrescentam uma camada adicional de¬†flexibilidade¬†para as redes neurais. Biases s√£o constantes associadas com cada neur√¥nio. Ao contr√°rio dos pesos, o bias n√£o est√° relacionado com dados espec√≠ficos de entrada do neur√¥nio, mas s√£o acrescentados aos dados de sa√≠da do neur√¥nios. Bias s√£o como um limite, permitindo que alguns neur√¥nios sejam ativados mesmo que a soma dos pesos dos dados que entraram n√£o seja o suficiente por conta pr√≥pria. Os biases introduzem um n√≠vel de adaptabilidade que garante que a rede possa aprender e fazer predi√ß√µes efetivamente. Para ficar claro, imagine um neur√¥nio que processe o n√≠vel de brilho do pixel de uma imagem, sem o bias, esse neur√¥nio s√≥ seria ativado quando o n√≠vel de brilho do pixel estivesse exatamente em um certo limite, mas colocando o bias, voc√™ permite que o neur√¥nio ative mesmo quando o brilho estiver um pouco menor ou acima do limite. Essa flexibilidade √© crucial porque os dados do mundo real raramente est√£o alinhados em um exato limite. Dessa forma, os biases permitem que os neur√¥nios ativem em v√°rias condi√ß√µes de entrada, fazendo com que as redes neurais fiquem mais robustas e capazes de lidar com dados complexos. Durante o treino, os biases s√£o ajustados para otimizar a performance da rede neural. 

![REDE NEURAL II](https://i.imgur.com/fSBTsUP.png)

- No exemplo acima, temos 224 pesos, que s√£o representados pelas conex√µes de sa√≠da ‚Üí entrada entre os neur√¥nios.
- Temos 26 biases, cada neur√¥nio tem o seu pr√≥prio (menos os da camada de entrada).
- Nesse sentido, temos 250 par√¢metros ajust√°veis.

### Processo de aprendizado: Forward e Backward Propagation

#### **A. Forward Propagation**
A propaga√ß√£o para frente √© a fase inicial de processamento dos dados de entrada atrav√©s da rede neural para formar o resultado ou predi√ß√£o.

1. **Camada de entrada**: Os dados s√£o inseridos na camada de entrada da rede neural.
2. **Soma ponderada dos pesos**: Cada neur√¥nio nas camadas subsequentes calcula a soma dos pesos dos dados que recebem, em que os pesos s√£o os par√¢metros ajust√°veis.
3. **Acrescentando os biases**: S√£o acrescentados os bias associados aos neur√¥nios para cada soma ponderada do passo anterior. Isso introduz um limite para ativa√ß√£o.
4. **Fun√ß√£o de Ativa√ß√£o**: Os resultados da soma ponderada com o bias √© passado atrav√©s de uma fun√ß√£o de ativa√ß√£o. Essa fun√ß√£o determina se o neur√¥nio deve ativar ou continuar dormente baseado no valor calculado.
5. **Propaga√ß√£o**: O resultado de sa√≠da uma das camadas vira a entrada para a camada seguinte, e o processo se repete at√© que a camada de sa√≠da produza a predi√ß√£o da rede.

**Essa l√≥gica de funcionamento foi implementada no notebook do reposit√≥rio.**

Abaixo segue um exemplo visual de funcionamento de rede neural:

![REDE NEURAL GATO](https://i.imgur.com/2kKW6Q5.png)
![REDE NEURAL GATO](https://i.imgur.com/AZvTtgI.png)
![REDE NEURAL GATO](https://i.imgur.com/iK7k2IV.png)

A foto de um gato foi inserida na rede neural e ela identificou ele corretamente como um gato, pode-se dizer que o neur√¥nio de gato na camada de sa√≠da foi o mais forte.

#### **B. Backward Propagation**

Depois que a rede neural fez uma predi√ß√£o, precisamos avaliar o qu√£o certeira ela foi e tamb√©m precisamos fazer ajustes para melhorar futuras predi√ß√µes.

1. **C√°lculos dos erros**: A predi√ß√£o da rede neural √© comparado com o fato real, o erro resultante, chamado de **loss** ou **cost**, mede a disparidade entre predi√ß√£o e realidade.
2. **Gradiente Descendente**: A propaga√ß√£o para tr√°s envolve minimizar esse erro. Para fazer isso, a rede calcula o gradiente do erro considerante os pesos e as biases. Esse gradiente aponta na dire√ß√£o da diminui√ß√£o mais acentuada do erro.
3. **Atualiza√ß√£o de Peso e Bias**: A rede neural usa as informa√ß√µes que obteve com o gradiente descendente para ajustar os pesos e os biases de toda a rede neural. O objetivo √© encontrar os valores que minimizam o erro.
4. **Processo de Itera√ß√£o**: Esse processo de forward e backward propagation √© repetido iterativamente em lotes de dados de treino, com cada itera√ß√£o, os pesos e os biases da rede se aproximam de valores que minimizam o erro.

**Em resumo, a propaga√ß√£o para tr√°s ajusta os par√¢metros da rede, fazendo com que fiquem com mais acur√°cia. Esse processo de itera√ß√£o continua at√© que a rede alcance um n√≠vel satisfat√≥rio de performance nos dados de treino**

### **C√°lculo da Sa√≠da do Neur√¥nio de forma visual**
 A sa√≠da do neur√¥nio √© dada por:  

$\text{Sa√≠da Neur√¥nio} = \text{Input} \times \text{Peso} + \text{Bias}\$
  
Ela se assemelha a uma fun√ß√£o de primeiro grau, esse seria o comportamento dela:

![NN_formula](https://i.imgur.com/lzEKc4S.gif)

### **Shape**:
Para trabalhar com redes neurais e deep learning, precisamos entender o conceito de **shape** ou formato nas linguagens de programa√ß√£o.

No contexto de **deep learning em python**, vamos ver as formas que o **numpy** reconhece:

![shape](https://i.imgur.com/sNTvXjn.png)

Acima temos uma lista com 4 elementos, de uma dimens√£o, ent√£o √© um vetor. Ela tem 4 elementos, ent√£o o shape dela √© (4, ).

![shape](https://i.imgur.com/rjvZZn2.png)

Acima temos uma lista com duas listas dentro, cada uma com 4 elementos. Isso √© uma matriz, o shape dela √© (2, 4).

![shape](https://i.imgur.com/5qYQjEk.png)

Acima temos uma lista, dentro dessa lista temos 3 outras listas, dentro dessas 3 outras listas, temos 2 listas em cada, em cada uma dessas duas listas temos 4 elementos.

Temos outra forma que √© o **tensor**, de forma bem rasa, um tensor √© um objeto que pode ser representado como um array, ele n√£o √© um simples array, mas no contexto de programa√ß√£o e deep learning ele pode ser representado e trabalhado como um array.  

### **Dot product**

Pegando o conceito dos tipos de array acima, podemos fazer opera√ß√µes entre eles, no caso do **Dot Product**, estamos falando da **multiplica√ß√£o** de dois arrays, e ele nos retorna somente um valor. Vale ressaltar que o dot product vem da biblioteca do numpy.

![dot_product](https://i.imgur.com/xh5txKP.png)

### Batches

Usamos lotes nos inputs na camada de entrada da rede porque assim facilita o aprendizado para o modelo. Se usarmos apenas uma entrada por vez para treinar o modelo, ele ter√° mais dificuldades para fazer os ajustes. Se usarmos mais entradas por vezes, o modelo ir√° se ajustar com mais facilidade.

![dot_product](https://i.imgur.com/dkR4r0K.gif)

No exemplo acima, os pontos que surgem s√£o os dados que pedimos para a rede se ajustar, como estamos passando dados de entrada com lotes de tamanho 1, percebe-se que a linha se movimenta e muito.

![dot_product](https://i.imgur.com/JESirG6.gif)

J√° nesse outro exemplo, a linha vai se adaptando, e quando se ajusta totalmente, percebe-se que ela vai se movendo muito pouco, isso porque estamos agora passando dados de entrada com lotes com tamanho 32.

### Fun√ß√µes de Ativa√ß√£o

Como vimos acima, os resultados de uma rede neural possuem uma rela√ß√£o linear, para introduzirmos uma **N√£o-Linearidade** na rede neural e assim possibilitarmos que ela compreenda melhor rela√ß√µes mais complexas nos dados, usamos as **fun√ß√µes de ativa√ß√£o**.

A ideia √© que as fun√ß√µes de ativa√ß√£o s√£o aplicadas nos resultados dos neur√¥nios, ap√≥s todas as opera√ß√µes.

![products](https://miro.medium.com/v2/resize:fit:828/format:webp/1*bUNxrEy2KjKNrwMRo8eS9w.png)

Depois de pegar os resultados $z_{1}$ e $z_{2}$ aplicamos eles na fun√ß√£o de ativa√ß√£o ùúé.

![activation function >](https://miro.medium.com/v2/resize:fit:278/format:webp/1*9DfvAg_pENO5MX0ELeY_kg.png)

#### Fun√ß√£o de ativa√ß√£o ReLU

**ReLU** significa Rectified Linear Unit, ou Unidade Linear Retificada. Ela √© a fun√ß√£o mais utilizada para fazer a maioria das tarefas de deep learning. 

A fun√ß√£o de ativa√ß√£o ReLU √© diferenci√°vel em todos os pontos (pode ser derivada em todos eles) exceto no ponto 0. Para valores maiores do que 0, consideramos aquele valor como o m√°ximo da fun√ß√£o.

Podemos dizer que ela √© assim:

**$f(x) = max\{0, z}\$**

Todos os valores negativos viram 0, e o m√°ximo do valor positivo √© considerado.

![relu](https://i.imgur.com/CTas9Z7.png)

Para a camada de sa√≠da, isso pode ser inadequado em muitos casos, imagine que temos resultados com valores -9000, -10, -11, -15.7, todas elas viram 0 ao passar pela ReLU, nesse sentido, essas sa√≠das perdem seu significado. 


#### Fun√ß√£o de ativa√ß√£o Softmax

A fun√ß√£o de ativa√ß√£o Softmax faz com que todos os valores n√£o percam seu significado, se um valor negativo entrar, ele ainda vai ter algum significado.

A fun√ß√£o softmax pode ser escrita assim:

**$$
\text{softmax}(z)_i = \frac{e^{z_i}}{\sum_{l=1}^{K} e^{z_j}}
$$**


O interessante dela √© que ela faz com que um vetor de K valores vire um outro vetor de K valores que a soma √© proxima de 1. Ao contr√°rio da ReLU, ela mant√©m as entradas menores e iguais a 0, e todos os valores que passam por essa fun√ß√£o ficam entre o intervalo de 0 e 1, nesse sentido, eles podem ser interpretados como probabilidades. Se uma das entradas √© pequena ou negativa, a softmax transforma em uma probabilidade pequena, e se uma das entradas for maior, ent√£o transforma essa entrada em uma probabilidade maior, mas que vai sempre estar entre 0 e 1.

As camadas finais de muitas redes neurais trazem saidas que s√£o valores n√£o escalonados convenientemente e que podem ser um pouco dif√≠ceis de trabalhar. Nessas camadas finais a softmax √© muito √∫til porque converte esses valores em uma distribui√ß√£o normalizada de probabilidade, que pode ser mostrada para o usu√°rio ou como entrada em outros sistemas.

![softmax](https://i.imgur.com/PMrTm4I.png)

**Funcionamento pr√°tico da Softmax**

![softmax1](https://i.imgur.com/dEVJ2GJ.png)

![softmax2](https://i.imgur.com/BhxSJ4j.png)

A softmax pega as entradas, faz a exponencial e normaliza.

### C√°lculo de Loss (Perda)

Queremos calcular o Loss para fazer a otimiza√ß√£o, para determinar o qu√£o errado o modelo est√°.

T√™m v√°rias maneiras de fazer esse c√°lculo, mas na maioria das vezes, a fun√ß√£o de Loss usada para casos de **classifica√ß√£o** √© a de **Categorical Cross-Entropy**

$$
L = -\sum_{j=1} y_{ij} \log(\hat{y}_{ij})
$$

Onde:
- \( L \) √© o valor da loss (perda) da amostra.
- \( y \) s√£o os valores alvo.
- \( y_{ij} \) √© o valor bin√°rio indicando se a amostra \( i \) pertence √† classe \( j \) (1 se pertence, 0 caso contr√°rio).
- \( \hat{y}_{ij} \) √© a probabilidade prevista da amostra \( i \) pertencer √† classe \( j \) (valores previstos).
- \( \log \) √© a fun√ß√£o logar√≠tmica natural.

Para entender melhor o funcionamento dessa fun√ß√£o, precisamos compreender a l√≥gica do **One Hot Encoding**.

#### One Hot Encoding

O One Hot Encoding √© usado para o c√°lculo de Loss da seguinte forma:

Suponhamos que temos um vetor com n classes de comprimento, ele √© preenchido com 0, exceto em que no index da classe alvo teremos 1.

Imagine que temos um vetor de 3 classes, e o index da classe alvo √© 0, ent√£o teremos o primeiro elemento do vetor como 1, e o resto 0.

![onehot](https://i.imgur.com/xUL2avo.png)

![onehot](https://i.imgur.com/3xGEaQp.png)

A rela√ß√£o disso com a fun√ß√£o de perda √© que na fun√ß√£o vamos passar as predi√ß√µes e os resultados reais com o one hot encoding. Por exemplo:

![onehot](https://i.imgur.com/QUDZqSC.png)

Aqui, usando o hot encoding, passamos que a classe alvo estava na posi√ß√£o 1 do vetor, ent√£o, em cima disso, ele faz a multiplica√ß√£o de cada classe com o log da sua predi√ß√£o, e no final soma tudo.

Com a ideia de One Hot Encoding, vamos para um exemplo mais pr√°tico:

Supondo que temos 3 classes a serem previstas (cachorro, gato e humano) e temos os resultados de tr√™s camadas que passaram pela softmax. Ilustrando ficaria dessa forma:

![exemplopratico](https://i.imgur.com/oIZeTko.png)

Ent√£o cachorros seriam representandos com 0, gatos com 1 e humanos 2, ficando assim:

![exemplopratico](https://i.imgur.com/dDv1h41.png)

Nesse sentido, temos que descobrir quais os n√≠veis de confian√ßa nas classes que est√£o certas. Para fazer isso, temos que pegar os valores √≠ndices da classe alvo e pegar os valores das sa√≠das da softmax que est√£o nesses √≠ndices.

No exemplo acima, a confian√ßa de cachorro vai ser 0.7 na primeira camada, 0.1 na segunda e 0.02 na terceira, e segue a mesma l√≥gica para gato e humano, percebe-se que os n√≠veis de confian√ßa s√£o maiores quando as classes est√£o certas. No exemplo, no primeiro lote vai ser cachorro, no segundo gato e no terceiro gato tamb√©m.




