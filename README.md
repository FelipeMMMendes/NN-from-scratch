# NN-from-scratch
Esse reposit√≥rio √© fruto da s√©rie de videos do canal **sentdex**, que implementou uma rede neural em python.

Uma rede neural √© um modelo que simula o modo de aprendizado humano, com suas sinapses e neur√¥nios.

![REDE NEURAL](https://i.imgur.com/PeldHjy.png)

- Temos uma camada de entrada no in√≠cio, camadas ocultas no meio (podem ser v√°rias) e uma camada de sa√≠da no final.
- Cada bolinha azul dessas √© um neur√¥nio e eles est√£o conectados uns com os outros.
- Em uma rede neural o processamento do dado come√ßa na camada de entrada, ele √© passado para as camadas ocultas e depois √© passado para a camada de sa√≠da.

Para treinar a rede neural, √© feito o balanceamento dos **pesos** e dos **biases.**

- **Pesos:** S√£o os padr√µes para a for√ßa do sinal do neur√¥nio, esse valor vai determinar a influ√™ncia dos dados de entrada no produto da sa√≠da de cada neur√¥nio. Pense neles como os n√∫meros que ajustam o impacto dos dados que est√£o entrando. Eles podem aumentar ou diminuir a import√¢ncia de informa√ß√µes espec√≠ficas. **Em ess√™ncia, os pesos s√£o a forma da rede neural aprender com os dados. Eles capturam as rela√ß√µes entre as features de entrada e de sa√≠da alvo, permitindo que a rede neural generalize e fa√ßa predi√ß√µes em dados que ela n√£o viu.**

- **Bias:** Acrescentam uma camada adicional de¬†flexibilidade¬†para as redes neurais. Biases s√£o constantes associadas com cada neur√¥nio. Ao contr√°rio dos pesos, o bias n√£o est√° relacionado com dados espec√≠ficos de entrada do neur√¥nio, mas s√£o acrescentados aos dados de sa√≠da do neur√¥nios. Bias s√£o como um limite, permitindo que alguns neur√¥nios sejam ativados mesmo que a soma dos pesos dos dados que entraram n√£o seja o suficiente por conta pr√≥pria. Os biases introduzem um n√≠vel de adaptabilidade que garante que a rede possa aprender e fazer predi√ß√µes efetivamente. Para ficar claro, imagine um neur√¥nio que processe o n√≠vel de brilho do pixel de uma imagem, sem o bias, esse neur√¥nio s√≥ seria ativado quando o n√≠vel de brilho do pixel estivesse exatamente em um certo limite, mas colocando o bias, voc√™ permite que o neur√¥nio ative mesmo quando o brilho estiver um pouco menor ou acima do limite. Essa flexibilidade √© crucial porque os dados do mundo real raramente est√£o alinhados em um exato limite. Dessa forma, os biases permitem que os neur√¥nios ativem em v√°rias condi√ß√µes de entrada, fazendo com que as redes neurais fiquem mais robustas e capazes de lidar com dados complexos. Durante o treino, os biases s√£o ajustados para otimizar a performance da rede neural. 

![REDE NEURAL II](https://i.imgur.com/fSBTsUP.png)

- No exemplo acima, temos 224 pesos, que s√£o representados pelas conex√µes de sa√≠da ‚Üí entrada entre os neur√¥nios.
- Temos 26 biases, cada neur√¥nio tem o seu pr√≥prio (menos os da camada de entrada).
- Nesse sentido, temos 250 par√¢metros ajust√°veis.

### Processo de aprendizado: Forward e Backward Propagation

#### **A. Forward Propagation**
A propaga√ß√£o para frente √© a fase inicial de processamento dos dados de entrada atrav√©s da rede neural para formar o resultado ou predi√ß√£o.

1. **Camada de entrada**: Os dados s√£o inseridos na camada de entrada da rede neural.
2. **Soma ponderada dos pesos**: Cada neur√¥nio nas camadas subsequentes calcula a soma dos pesos dos dados que recebem, em que os pesos s√£o os par√¢metros ajust√°veis.
3. **Acrescentando os biases**: S√£o acrescentados os bias associados aos neur√¥nios para cada soma ponderada do passo anterior. Isso introduz um limite para ativa√ß√£o.
4. **Fun√ß√£o de Ativa√ß√£o**: Os resultados da soma ponderada com o bias √© passado atrav√©s de uma fun√ß√£o de ativa√ß√£o. Essa fun√ß√£o determina se o neur√¥nio deve ativar ou continuar dormente baseado no valor calculado.
5. **Propaga√ß√£o**: O resultado de sa√≠da uma das camadas vira a entrada para a camada seguinte, e o processo se repete at√© que a camada de sa√≠da produza a predi√ß√£o da rede.

**Essa l√≥gica de funcionamento foi implementada no notebook do reposit√≥rio.**

Abaixo segue um exemplo visual de funcionamento de rede neural:

![REDE NEURAL GATO](https://i.imgur.com/2kKW6Q5.png)
![REDE NEURAL GATO](https://i.imgur.com/AZvTtgI.png)
![REDE NEURAL GATO](https://i.imgur.com/iK7k2IV.png)

A foto de um gato foi inserida na rede neural e ela identificou ele corretamente como um gato, pode-se dizer que o neur√¥nio de gato na camada de sa√≠da foi o mais forte.

#### **B. Backward Propagation**

Depois que a rede neural fez uma predi√ß√£o, precisamos avaliar o qu√£o certeira ela foi e tamb√©m precisamos fazer ajustes para melhorar futuras predi√ß√µes.

1. **C√°lculos dos erros**: A predi√ß√£o da rede neural √© comparado com o fato real, o erro resultante, chamado de **loss** ou **cost**, mede a disparidade entre predi√ß√£o e realidade.
2. **Gradiente Descendente**: A propaga√ß√£o para tr√°s envolve minimizar esse erro. Para fazer isso, a rede calcula o gradiente do erro considerante os pesos e as biases. Esse gradiente aponta na dire√ß√£o da diminui√ß√£o mais acentuada do erro.
3. **Atualiza√ß√£o de Peso e Bias**: A rede neural usa as informa√ß√µes que obteve com o gradiente descendente para ajustar os pesos e os biases de toda a rede neural. O objetivo √© encontrar os valores que minimizam o erro.
4. **Processo de Itera√ß√£o**: Esse processo de forward e backward propagation √© repetido iterativamente em lotes de dados de treino, com cada itera√ß√£o, os pesos e os biases da rede se aproximam de valores que minimizam o erro.

**Em resumo, a propaga√ß√£o para tr√°s ajusta os par√¢metros da rede, fazendo com que fiquem com mais acur√°cia. Esse processo de itera√ß√£o continua at√© que a rede alcance um n√≠vel satisfat√≥rio de performance nos dados de treino**

### **C√°lculo da Sa√≠da do Neur√¥nio de forma visual**
 A sa√≠da do neur√¥nio √© dada por:  

$\text{Sa√≠da Neur√¥nio} = \text{Input} \times \text{Peso} + \text{Bias}\$
  
Ela se assemelha a uma fun√ß√£o de primeiro grau, esse seria o comportamento dela:

![NN_formula](https://i.imgur.com/lzEKc4S.gif)

### **Shape**:
Para trabalhar com redes neurais e deep learning, precisamos entender o conceito de **shape** ou formato nas linguagens de programa√ß√£o.

No contexto de **deep learning em python**, vamos ver as formas que o **numpy** reconhece:

![shape](https://i.imgur.com/sNTvXjn.png)

Acima temos uma lista com 4 elementos, de uma dimens√£o, ent√£o √© um vetor. Ela tem 4 elementos, ent√£o o shape dela √© (4, ).

![shape](https://i.imgur.com/rjvZZn2.png)

Acima temos uma lista com duas listas dentro, cada uma com 4 elementos. Isso √© uma matriz, o shape dela √© (2, 4).

![shape](https://i.imgur.com/5qYQjEk.png)

Acima temos uma lista, dentro dessa lista temos 3 outras listas, dentro dessas 3 outras listas, temos 2 listas em cada, em cada uma dessas duas listas temos 4 elementos.

Temos outra forma que √© o **tensor**, de forma bem rasa, um tensor √© um objeto que pode ser representado como um array, ele n√£o √© um simples array, mas no contexto de programa√ß√£o e deep learning ele pode ser representado e trabalhado como um array.  

### **Dot product**

Pegando o conceito dos tipos de array acima, podemos fazer opera√ß√µes entre eles, no caso do **Dot Product**, estamos falando da **multiplica√ß√£o** de dois arrays, e ele nos retorna somente um valor. Vale ressaltar que o dot product vem da biblioteca do numpy.

![dot_product](https://i.imgur.com/xh5txKP.png)

### Batches

Usamos lotes nos inputs na camada de entrada da rede porque assim facilita o aprendizado para o modelo. Se usarmos apenas uma entrada por vez para treinar o modelo, ele ter√° mais dificuldades para fazer os ajustes. Se usarmos mais entradas por vezes, o modelo ir√° se ajustar com mais facilidade.

![dot_product](https://i.imgur.com/dkR4r0K.gif)

No exemplo acima, os pontos que surgem s√£o os dados que pedimos para a rede se ajustar, como estamos passando dados de entrada com lotes de tamanho 1, percebe-se que a linha se movimenta e muito.

![dot_product](https://i.imgur.com/JESirG6.gif)

J√° nesse outro exemplo, a linha vai se adaptando, e quando se ajusta totalmente, percebe-se que ela vai se movendo muito pouco, isso porque estamos agora passando dados de entrada com lotes com tamanho 32.

### Fun√ß√µes de Ativa√ß√£o

Como vimos acima, os resultados de uma rede neural possuem uma rela√ß√£o linear, para introduzirmos uma **N√£o-Linearidade** na rede neural e assim possibilitarmos que ela compreenda melhor rela√ß√µes mais complexas nos dados, usamos as **fun√ß√µes de ativa√ß√£o**.

A ideia √© que as fun√ß√µes de ativa√ß√£o s√£o aplicadas nos resultados dos neur√¥nios, ap√≥s todas as opera√ß√µes.

![products](https://miro.medium.com/v2/resize:fit:828/format:webp/1*bUNxrEy2KjKNrwMRo8eS9w.png)

Depois de pegar os resultados $z_{1}$ e $z_{2}$ aplicamos eles na fun√ß√£o de ativa√ß√£o ùúé.

![activation function >](https://miro.medium.com/v2/resize:fit:278/format:webp/1*9DfvAg_pENO5MX0ELeY_kg.png)

#### Fun√ß√£o de ativa√ß√£o ReLU

**ReLU** significa Rectified Linear Unit, ou Unidade Linear Retificada. Ela √© a fun√ß√£o mais utilizada para fazer a maioria das tarefas de deep learning. 

A fun√ß√£o de ativa√ß√£o ReLU √© diferenci√°vel em todos os pontos (pode ser derivada em todos eles) exceto no ponto 0. Para valores maiores do que 0, consideramos aquele valor como o m√°ximo da fun√ß√£o.

Podemos dizer que ela √© assim:

$f(x) = max{0, z}

Todos os valores negativos viram 0, e o m√°ximo do valor positivo √© considerado.


